{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jepaNV8cVVZKL0X2ZjEGq88jRGcYtFWM",
      "authorship_tag": "ABX9TyPOEBuBYCludozezWJj3DkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushalgouda-Patil/Neural-Ninjas/blob/main/eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCvgfLtf9J4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6167019d-6446-4774-ce24-bf80f7333f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ANN_classifiction'...\n",
            "remote: Enumerating objects: 3724, done.\u001b[K\n",
            "remote: Counting objects: 100% (456/456), done.\u001b[K\n",
            "remote: Compressing objects: 100% (456/456), done.\u001b[K\n",
            "remote: Total 3724 (delta 0), reused 456 (delta 0), pack-reused 3268\u001b[K\n",
            "Receiving objects: 100% (3724/3724), 61.38 MiB | 30.60 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sumitmeharwade/ANN_classifiction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dWTwrFLYBVA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "oAw8Hx6JEsUY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv2.imread(\"/content/ANN_classifiction/MY_data/train/Apple/images.jpeg\")"
      ],
      "metadata": {
        "id": "cGMzxbICFnMG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTpQUDD2F7oB",
        "outputId": "e920fb5f-0318-4d1f-8b55-34ae2cdb36f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(183, 275, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the paths to your dataset\n",
        "train_dataset_path = '/content/ANN_classifiction/MY_data/train'\n",
        "test_dataset_path = '/content/ANN_classifiction/MY_data/test'\n",
        "\n",
        "# Data augmentation for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Specify the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle the test data\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(20, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_generator, epochs=11, validation_data=test_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UeOJqC8IfEQ",
        "outputId": "ec57546c-1750-4a0d-ec65-f5b78a7f5a31"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2301 images belonging to 10 classes.\n",
            "Found 1025 images belonging to 10 classes.\n",
            "Epoch 1/11\n",
            "72/72 [==============================] - 33s 421ms/step - loss: 3.6387 - accuracy: 0.2729 - val_loss: 1.9089 - val_accuracy: 0.3190\n",
            "Epoch 2/11\n",
            "72/72 [==============================] - 30s 424ms/step - loss: 1.5836 - accuracy: 0.4085 - val_loss: 1.8751 - val_accuracy: 0.3746\n",
            "Epoch 3/11\n",
            "72/72 [==============================] - 31s 438ms/step - loss: 1.3754 - accuracy: 0.5080 - val_loss: 1.8293 - val_accuracy: 0.4107\n",
            "Epoch 4/11\n",
            "72/72 [==============================] - 35s 482ms/step - loss: 1.2899 - accuracy: 0.5293 - val_loss: 1.7924 - val_accuracy: 0.4254\n",
            "Epoch 5/11\n",
            "72/72 [==============================] - 30s 421ms/step - loss: 1.1619 - accuracy: 0.5876 - val_loss: 1.8651 - val_accuracy: 0.4517\n",
            "Epoch 6/11\n",
            "72/72 [==============================] - 31s 436ms/step - loss: 1.0875 - accuracy: 0.6058 - val_loss: 1.7673 - val_accuracy: 0.4790\n",
            "Epoch 7/11\n",
            "72/72 [==============================] - 30s 419ms/step - loss: 1.0191 - accuracy: 0.6423 - val_loss: 1.9706 - val_accuracy: 0.4673\n",
            "Epoch 8/11\n",
            "72/72 [==============================] - 30s 419ms/step - loss: 0.9414 - accuracy: 0.6780 - val_loss: 1.9055 - val_accuracy: 0.4956\n",
            "Epoch 9/11\n",
            "72/72 [==============================] - 30s 420ms/step - loss: 0.8862 - accuracy: 0.6867 - val_loss: 1.9415 - val_accuracy: 0.4790\n",
            "Epoch 10/11\n",
            "72/72 [==============================] - 30s 421ms/step - loss: 0.8805 - accuracy: 0.6884 - val_loss: 2.0396 - val_accuracy: 0.4761\n",
            "Epoch 11/11\n",
            "72/72 [==============================] - 32s 441ms/step - loss: 0.8290 - accuracy: 0.7036 - val_loss: 2.3037 - val_accuracy: 0.4498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "image_path = '/content/ANN_classifiction/MY_data/predict/00.jpeg'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0rRNj_WJT5a",
        "outputId": "6943ffe6-c571-4b8e-bc62-aad937c50c0d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicted class: cherry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "dataset_path = '/content/ANN_classifiction/data'\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(15, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(train_generator, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMuCfgoFKOYr",
        "outputId": "c83b1f2f-2595-4eef-b47b-f12f579a3392"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 451 images belonging to 2 classes.\n",
            "Epoch 1/3\n",
            "15/15 [==============================] - 7s 375ms/step - loss: 4.6110 - accuracy: 0.5299\n",
            "Epoch 2/3\n",
            "15/15 [==============================] - 8s 536ms/step - loss: 1.1603 - accuracy: 0.7051\n",
            "Epoch 3/3\n",
            "15/15 [==============================] - 6s 384ms/step - loss: 0.6293 - accuracy: 0.7140\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f9ff24ea950>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "image_path = '/content/ANN_classifiction/data/porcupines/1-porcupine-moswe590a-590x390.jpg'\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "\n",
        "predictions = model2.predict(img_array)\n",
        "\n",
        "\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y8LO9cbLYPl",
        "outputId": "0af88692-806a-44d5-f4fc-a7cdc246851f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted class: porcupines\n"
          ]
        }
      ]
    }
  ]
}